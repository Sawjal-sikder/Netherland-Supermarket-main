# Netherlands Supermarket Scraper

A comprehensive Python scraping system for Netherlands supermarket websites. Built with clean architecture principles and focused on essential product data collection with support for both full product catalogs and daily offer tracking.

## ğŸ¯ Features

- **Multi-Supermarket Support**: 9 major Dutch supermarkets (Dirk, AH, Aldi, Jumbo, Lidl, Plus, Coop, Dekamarkt, Hoogvliet)
- **Dual Scraping Modes**: Full product scraping (weekly) + Offer scraping (daily)
- **Essential Data Only**: Product name, category, price, unit amount, price per unit, supermarket, discounts, and search tags
- **Clean Architecture**: Object-oriented design with SOLID principles
- **Robust Error Handling**: Comprehensive logging and graceful failure recovery
- **Database Integration**: MySQL storage with optimized schema
- **Easy Maintenance**: Well-documented, modular code structure
- **Flexible Scheduling**: Different frequencies for different scraping needs

## ğŸª Supported Supermarkets

| Supermarket | Product Scraping | Offer Scraping | Implementation Status |
|-------------|------------------|----------------|----------------------|
| Dirk van den Broek | âœ… Full | âœ… Offers | Fully Implemented |
| Albert Heijn | âœ… Full | âœ… Offers | Fully Implemented |
| Aldi | âœ… Full | âœ… Offers | Fully Implemented |
| Jumbo | âœ… Full | âœ… Offers | Fully Implemented |
| Lidl | âœ… Full | ğŸ”„ Basic | Core Structure Ready |
| Plus | âœ… Full | âœ… Basic | Core Implementation |
| Coop | âŒ | âœ… Basic | Offers Only |
| Dekamarkt | âœ… Full | ğŸ”„ Basic | Core Structure Ready |
| Hoogvliet | âœ… Full | ğŸ”„ Basic | Core Structure Ready |

## ğŸ”„ Two Scraping Modes

### 1. Weekly Full Product Scraping
- **Purpose**: Complete product catalog
- **Frequency**: Weekly
- **Command**: `python run_scrapers.py [supermarket]`
- **Target**: All products from main product pages

### 2. Daily Offers Scraping (NEW)
- **Purpose**: Find new deals and promotions  
- **Frequency**: Daily
- **Command**: `python run_offers_scraper.py --supermarket [name]`
- **Target**: Products on offer/promotion pages

## ğŸ—ï¸ Architecture

### Core Components

```
â”œâ”€â”€ database.py              # Database operations and data models
â”œâ”€â”€ base_scraper.py          # Abstract base scraper class
â”œâ”€â”€ run_scrapers.py          # Weekly full product scraping
â”œâ”€â”€ run_offers_scraper.py    # Daily offers scraping (NEW)
â”œâ”€â”€ config.py                # Configuration management
â”œâ”€â”€ database_schema.sql      # Database schema
â”œâ”€â”€ Supermarkets/            # Regular product scrapers
â”‚   â”œâ”€â”€ dirk.py             # Dirk van den Broek scraper
â”‚   â”œâ”€â”€ ah.py               # Albert Heijn scraper
â”‚   â”œâ”€â”€ aldi.py             # Aldi scraper
â”‚   â”œâ”€â”€ jumbo.py            # Jumbo scraper
â”‚   â””â”€â”€ ...                 # Other supermarket scrapers
â””â”€â”€ Supermarkets/offers/     # Specialized offer scrapers (NEW)
    â”œâ”€â”€ dirk_offers.py      # Dirk offers scraper
    â”œâ”€â”€ ah_offers.py        # AH offers scraper
    â”œâ”€â”€ aldi_offers.py      # Aldi offers scraper
    â”œâ”€â”€ jumbo_offers.py     # Jumbo offers scraper
    â””â”€â”€ other_offers.py     # Plus, Coop, Dekamarkt, etc.
```

### Design Patterns Used

- **Template Method Pattern**: Base scraper defines common workflow
- **Inheritance**: Offer scrapers extend regular scrapers
- **Context Manager**: Automatic database connection handling
- **Data Classes**: Type-safe product data structures
- **Factory Pattern**: Scraper initialization and configuration
- **Strategy Pattern**: Different scraping approaches per supermarket
- **Command Pattern**: CLI interface for different scraping modes

## ğŸ“Š Data Collected

For each product, the system collects:

- **Product Name**: Full product title
- **Category**: Product category classification
- **Price**: Current selling price
- **Unit Amount**: Package size/weight (e.g., "500g", "1 liter")
- **Price Per Unit**: Calculated price per unit (â‚¬/kg, â‚¬/liter, etc.)
- **Supermarket**: Store name
- **Discount Info**: Discount type and percentage (if applicable)
- **Search Tags**: Keywords for product discovery
- **Promotion Period**: Start/end dates for offers (when available)

## ğŸš€ Quick Start

### Daily Offers Scraping

```bash
# Scrape offers from all supermarkets
python run_offers_scraper.py --supermarket all

# Scrape offers from specific supermarket
python run_offers_scraper.py --supermarket dirk

# Scrape offers from multiple supermarkets
python run_offers_scraper.py --multiple dirk ah aldi

# Test with limited products
python run_offers_scraper.py --supermarket dirk --limit 10
```

### Weekly Full Product Scraping

```bash
# Scrape all products from specific supermarket
python run_scrapers.py dirk

# Scrape with product limit for testing
python run_scrapers.py dirk --product-limit 100
```

### 1. Prerequisites

- Python 3.8+
- MySQL Server
- Required Python packages (see requirements.txt)

### 2. Installation

```bash
# Clone repository
git clone <repository-url>
cd netherland-supermarket

# Install dependencies
pip install -r requirements.txt
```

### 3. Database Setup

```bash
# Create database and tables
mysql -u root -p < database_schema.sql
```

### 4. Configuration

```bash
# Create environment file
python config.py

# Edit .env with your database credentials
cp .env.example .env
# Edit .env file with your MySQL credentials
```

### 5. Run Scrapers

```bash
# Run all scrapers
python main_new.py

# Run specific scraper
python main_new.py dirk
python main_new.py ah

# Run multiple specific scrapers
python main_new.py dirk,ah
```

## ğŸ“‹ Configuration

### Database Configuration

Edit `.env` file:

```env
DB_HOST=localhost
DB_USER=root
DB_PASSWORD=your_password
DB_NAME=supermarket_products
DB_PORT=3306
```

### Scraping Configuration

Modify `config.py` for advanced settings:

```python
'scraping': {
    'request_timeout': 30,
    'retry_attempts': 3,
    'delay_between_requests': 1.0,
    'max_products_per_category': None,  # Limit for testing
    'log_level': 'INFO'
}
```

## ğŸ› ï¸ Development

### Adding New Supermarket

1. Create new scraper class inheriting from `BaseScraper`:

```python
from base_scraper import BaseScraper

class NewSupermarketScraper(BaseScraper):
    def __init__(self, db_manager):
        super().__init__(db_manager, "NewSupermarket")
    
    def scrape_products(self) -> List[Product]:
        # Implement scraping logic
        pass
```

2. Add to `main_new.py` scraper initialization:

```python
('new_supermarket', NewSupermarketScraper, "New Supermarket")
```

### Database Schema

The simplified schema focuses on essential tables:

- `supermarkets`: Store information
- `categories`: Product categories
- `products`: Main product data
- `price_history`: Price tracking over time
- `scraping_sessions`: Scraping session logs

### Testing Individual Scrapers

Each scraper has a built-in test function:

```bash
# Test Dirk scraper
python dirk_new.py

# Test AH scraper
python ah_new.py
```

## ğŸ“ˆ Monitoring and Logs

### Log Files

Logs are stored in `logs/` directory with timestamp:
- `scraping_YYYYMMDD_HHMMSS.log`

### Database Monitoring

Check scraping sessions:

```sql
-- Recent scraping sessions
SELECT * FROM scraping_sessions ORDER BY created_at DESC LIMIT 10;

-- Products added today
SELECT COUNT(*) FROM products WHERE created_at >= CURDATE();

-- Price changes
SELECT * FROM price_history WHERE created_at >= CURDATE();
```

## ğŸ”§ Troubleshooting

### Common Issues

**Database Connection Error**
```bash
# Check MySQL service
net start mysql

# Verify credentials in .env file
```

**Scraping Failures**
```bash
# Check logs for specific errors
tail -f logs/scraping_*.log

# Test individual scrapers
python dirk_new.py
```

**Missing Dependencies**
```bash
# Reinstall requirements
pip install -r requirements.txt --upgrade
```

### Performance Optimization

- Adjust `delay_between_requests` in config
- Set `max_products_per_category` for testing
- Use database indexes for faster queries
- Monitor memory usage during large scrapes

## ğŸ“š API Reference

### Product Data Class

```python
@dataclass
class Product:
    product_id: str
    name: str
    category: str
    supermarket: str
    price: float
    unit_amount: str
    unit_type: UnitType
    price_per_unit: float
    discount_type: Optional[str] = None
    original_price: Optional[float] = None
    search_tags: str = ""
    image_url: Optional[str] = None
```

### Database Manager

```python
# Save product
db_manager.save_product(product)

# Create scraping session
session_id = db_manager.create_scraping_session()

# Update session results
db_manager.update_scraping_session(session_id, scraper, count, success)
```

## ğŸ¤ Contributing

1. Follow existing code style and patterns
2. Add comprehensive error handling
3. Include logging for debugging
4. Update documentation for new features
5. Test thoroughly before committing

## ğŸ“„ License

This project is for educational and research purposes. Please respect the terms of service of the scraped websites.

## ğŸ”„ Version History

### v2.0 (Current - Simplified)
- Complete architecture overhaul
- Focused on essential data only
- Clean OOP design with SOLID principles
- Improved error handling and logging
- Simplified database schema

### v1.0 (Legacy)
- Initial complex implementation
- Multiple features and data points
- More complex database schema
- Legacy files: `dirk.py`, `ah.py`, `main.py`

---

For questions or support, please check the logs first, then review the troubleshooting section above.
